You should always try to decrease size of data for shuffling to increase application performance.
One common solution to achieve this is, always filter data before shuffle phase rather than after.

Always try to avoid empty partition. After filter use coalesce

If your job is taking a long time and your cluster is not utilised completely, try to use repartition operation

MEMORY_ONLY  cache will put pressure on GC. Alternate caching is MEMORY_ONLY_SER, MEMORY_AND_DISK
Use LZF compression to improve shuffle performance
conf.set("spark.io.compression.codec","lzf")

Turn on speculative execution to help prevent stragglers.
conf.set("spark.speculation","true")


Number of partitions should be  2 times #cores
For example, if you have 100 cores in the clusters, a good starting point for number of partitions is around 200. From there on, you can continue to keep increasing the number of partitions until you can see that you get a good balance of concurrency and task execution time.


Now, the total number of partitions per job is
number of partitions per application = (#consumers) * (batchInterval / blockInterval)



ReduceByKey Vs GroupByKey
Prefer ReduceByKey over GroupByKey


 Checkpointing waits until the end of a job, and launches another job to finish checkpoint. An RDD which needs to be checkpointed will be computed twice; thus it is suggested to do a rdd.cache() before rdd.checkpoint(). In this case, the second job will not recompute the RDD. Instead, it will just read cache
 
 